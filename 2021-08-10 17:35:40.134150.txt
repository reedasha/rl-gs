state: [[-0.9461393962607827,0.8710997048597843],[-0.9461393962607827,0.4359622873430404],[-0.9461393962607827,-0.29864563438954944],[-0.9461393962607827,-0.9335434654897398],[-0.41072436451892325,0.9711500278108317],[-0.21067767276544475,0.33625219671064127],[-0.31124156516059187,-0.29864563438954944],[-0.31124156516059187,-0.9335434654897398],[0.32365626593959873,0.9711500278108317],[0.32365626593959873,0.33625219671064127],[0.32365626593959873,-0.29864563438954944],[0.32365626593959873,-0.9335434654897398],[0.9585540970397889,0.7700242925698481],[0.9585540970397889,0.43663835809951573],[0.8581553977709231,-0.29864563438954944],[0.9585540970397889,-1.133316157887717]]rewards: [-0.002210399617107228, -0.0017556014662511998, -0.007026272481412743, -0.013139573427764617, -0.0151502916064703, -0.018012438670013342, -0.021363481424165442, -0.016430961696442203, -0.01911441044816975, -0.020600312891009942]
scores: [-0.13480374372880677]
policy loss: tensor(-5.6246, grad_fn=<SumBackward0>)
best_mi: 2.6633534554480187
state: [[-0.9467961622624034,0.8722581265663828],[-0.9467961622624034,0.33637810276104374],[-0.9467961622624034,-0.29894067682202863],[-1.144920485217685,-0.934259456405101],[-0.31147738267933106,0.9716968823441161],[-0.31147738267933106,0.33637810276104374],[-0.21249535143390616,-0.29894067682202863],[-0.21176569912481036,-0.934259456405101],[0.3238413969037413,0.9716968823441161],[0.22435989126379513,0.33637810276104374],[0.3238413969037413,-0.29894067682202863],[0.3238413969037413,-1.0331261347868108],[0.959160176486814,0.8714134133497533],[0.959160176486814,0.23592538357299428],[0.959160176486814,-0.29894067682202863],[0.959160176486814,-0.8347172415753664]]rewards: [0.004690755633704136, -0.0008677443525884065, 1.839488377264331e-05, -0.0011874333966304107, 0.00681894963239138, 0.0003781276283523205, -0.00021138165445844237, 0.00477352741345527, 0.007599686393357619, 0.005501851132704516]
scores: [-0.13480374372880677, 0.027514733314060624]
policy loss: tensor(1.1501, grad_fn=<SumBackward0>)
best_mi: 2.6753163291735187
state: [[-0.9469701953643442,0.8593192560002556],[-0.9469701953643442,0.22749833501580513],[-0.9469701953643442,-0.3031387034785196],[-0.9469701953643442,-0.9345081467584287],[-0.31560075208443483,0.959600183081299],[-0.31560075208443483,0.3282307398013896],[-0.31560075208443483,-0.40296697776837004],[-0.31560075208443483,-0.9345081467584287],[0.3154950547503874,0.959600183081299],[0.3155460579349667,0.3282307398013896],[0.31576869119547435,-0.3031387034785196],[0.31576869119547435,-0.9345081467584287],[0.9471381344753834,1.0597054986548164],[0.8465780022452415,0.3282307398013896],[1.0468510235228061,-0.3031387034785196],[0.9471381344753834,-0.9345081467584287]]rewards: [0.005862349419506696, -0.004630071493393562, -0.0034288405696294433, -0.006005583605032783, 0.004963069238952844, 0.007680369136780829, 0.009447019323390649, -0.006687772824268912, 0.004614401246056499, 0.007282424430070655]
scores: [-0.13480374372880677, 0.027514733314060624, 0.019097364302433473]
policy loss: tensor(0.8241, grad_fn=<SumBackward0>)
best_mi: 2.6701572222029784
state: [[-0.8554391456820009,0.9689026338021922],[-1.056070097563338,0.32298685545405154],[-0.9564167160722467,-0.32292892289408925],[-0.9564167160722467,-0.9688447012422303],[-0.31050093772410553,0.8667743819911623],[-0.31050093772410553,0.32298685545405154],[-0.31050093772410553,-0.32292892289408925],[-0.31050093772410553,-0.8684447456660805],[0.23559265694424633,0.9689026338021922],[0.23523831255024324,0.32298685545405154],[0.3354148406240353,-0.32292892289408925],[0.3354148406240353,-0.9688447012422303],[0.9813306189721761,0.9689026338021922],[1.0814480674078752,0.22270069646225105],[0.9813306189721761,-0.32292892289408925],[0.8805764701914669,-0.8672937064952464]]rewards: [0.0069796759442004586, 0.004772492254190297, 0.003144443674163, -0.0014936112804253554, 0.004257414927566927, 0.00595960397477624, 0.006800704559790205, 0.009975138505698311, 0.0015866877976682403, 0.003284343669067269]
scores: [-0.13480374372880677, 0.027514733314060624, 0.019097364302433473, 0.04526689402669559]
policy loss: tensor(1.8207, grad_fn=<SumBackward0>)
best_mi: 2.6720922398284532
state: [[-0.9527484306491593,0.9652828591883429],[-0.9527484306491593,0.33004895567894266],[-0.9527484306491593,-0.3051849478304579],[-0.8529229191190345,-0.8411572551714105],[-0.3175145271397587,0.9652828591883429],[-0.3175145271397587,0.33004895567894266],[-0.3175145271397587,-0.3051849478304579],[-0.2175275368757053,-0.9404188513398586],[0.21722062386271151,0.9652828591883429],[0.2173898582913583,0.33004895567894266],[0.3177193763696418,-0.3051849478304579],[0.3177193763696418,-1.138436208996224],[1.053392578981509,0.9652828591883429],[0.9529532798790421,0.22989265437898343],[0.9529532798790421,-0.3051849478304579],[0.8518909557285477,-0.9404188513398586]]rewards: [0.01189615111425768, 0.005701227757893168, 0.01081490123693607, 0.0075402919850562355, 0.010647911492284834, 0.015232780985804606, 0.01387414652454444, 0.009813220156494662, 0.00935359191879881, 0.010270623911120769]
scores: [-0.13480374372880677, 0.027514733314060624, 0.019097364302433473, 0.04526689402669559, 0.10514484708319127]
policy loss: tensor(3.9268, grad_fn=<SumBackward0>)
best_mi: 2.6751939682235113
